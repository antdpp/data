import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
from keras.models import load_model
import os
import pandas as pd

# Load the initial setup
wd = os.getcwd()

# Load contract grid:
logMoneyness = pd.read_csv(os.path.join(wd, 'data', 'logMoneyness.txt'), delimiter=",", header=None).values.flatten()
expiries = pd.read_csv(os.path.join(wd, 'data', 'expiries.txt'), delimiter=",", header=None).values.flatten()

print("LogMoneyness:", logMoneyness)
print("Expiries:", expiries)

# Verify lengths
print(f"Number of logMoneyness values: {len(logMoneyness)}")
print(f"Number of expiries values: {len(expiries)}")

# Set useful parameters
nIn = 7
nOut = 175
nXi = 4

# Load training data
data_train = pd.read_csv(os.path.join(wd, 'data', 'training_and_test_data', 'rbergomi', 'rbergomi_training_data_1.csv'), delimiter=",").values
x_train = data_train[:, :nIn]
y_train = data_train[:, nIn:nIn + nOut]
data_train = None

# Load test data
data_test = pd.read_csv(os.path.join(wd, 'data', 'training_and_test_data', 'rbergomi', 'rbergomi_test_data_1.csv'), delimiter=",").values
x_valid = data_test[:, :nIn]
y_valid = data_test[:, nIn:nIn + nOut]
data_test = None

# Normalize data
tmp1 = np.reshape(np.array([0.50, 3.50, 0.00]), (1, 3))
tmp2 = np.reshape(np.array([0.00, 0.75, -1.00]), (1, 3))
ub = np.concatenate((tmp1, np.tile(1, (1, nXi))), 1)
lb = np.concatenate((tmp2, np.tile(0.0025, (1, nXi))), 1)

def myscale(x):
    res = np.zeros(nIn)
    for i in range(nIn):
        res[i] = (x[i] - (ub[0, i] + lb[0, i]) * 0.5) * 2 / (ub[0, i] - lb[0, i])
    return res

def myinverse(x):
    res = np.zeros(nIn)
    for i in range(nIn):
        res[i] = x[i] * (ub[0, i] - lb[0, i]) * 0.5 + (ub[0, i] + lb[0, i]) * 0.5
    return res

# Scale inputs
x_train_mod = np.array([myscale(x) for x in x_train])
x_valid_mod = np.array([myscale(x) for x in x_valid])

# Scale and normalize output
from sklearn.preprocessing import StandardScaler
scale_y = StandardScaler()
y_train_mod = scale_y.fit_transform(y_train)
y_valid_mod = scale_y.transform(y_valid)

# Load the trained neural network model
model = load_model(os.path.join(wd, 'data', 'neural_network_weights', 'rbergomi', 'rbergomi_model_1.h5'),
                   custom_objects={'root_mean_squared_error': root_mean_squared_error})

# Define inverse transform function
def xinversetransform(x):
    return scale_y.inverse_transform(x)

# Make predictions using the trained neural network
prediction = xinversetransform(model.predict(x_valid_mod))

# Compute and plot relative errors
# For demonstration, we will handle the errors manually based on data size
maturities_dim = len(np.unique(expiries))
strikes_dim = nOut // maturities_dim  # Assume equal distribution of logMoneyness values for each maturity

# Reshape errors for plotting
errors = {
    "Average relative error": np.mean(100 * np.abs((y_valid - prediction) / y_valid), axis=0),
    "Std relative error": 100 * np.std(np.abs((y_valid - prediction) / y_valid), axis=0),
    "Maximum relative error": 100 * np.max(np.abs((y_valid - prediction) / y_valid), axis=0)
}

plt.figure(1, figsize=(24, 12))  # Increase the figsize to make the subplots larger

for i, (title, err) in enumerate(errors.items(), start=1):
    ax = plt.subplot(1, 3, i)
    plt.title(title, fontsize=15, y=1.04)
    im = plt.imshow(err.reshape((maturities_dim, strikes_dim)).T, aspect='auto')
    cbar = plt.colorbar(im, format=mtick.PercentFormatter())
    cbar.ax.tick_params(labelsize=12)
    ax.set_xticks(np.arange(maturities_dim))
    ax.set_xticklabels([f"{x:.3f}" for x in np.unique(expiries)])
    ax.set_yticks(np.arange(strikes_dim))
    ax.set_yticklabels([f"{x:.4f}" for x in logMoneyness[:strikes_dim]])
    plt.xlabel("Maturity", fontsize=15, labelpad=5)
    plt.ylabel("Log-Moneyness", fontsize=15, labelpad=5)

# Adjust layout to prevent overlap and save the plot
plt.tight_layout()
plt.subplots_adjust(wspace=0.4, hspace=0.4)  # Adjust spacing between subplots
plt.savefig('rBergomiTermStructureNNErrors.PNG', dpi=300)
plt.show()

